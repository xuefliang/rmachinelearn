---
title: "MLR"
author: "data"
date: "May 25, 2017"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(caret)
library(mlr)
library(data.table)
library(plotly)
library(ROSE)
library(xgboost)
train <- fread("~/Dropbox/rmachinelearn/census/train.csv",na.string=c(""," ","?","NA",NA)) 
test <- fread("~/Dropbox/rmachinelearn/census/test.csv",na.string=c(""," ","?","NA",NA))
```

#数据探索DATA EXPLORATION
```{r}
dim(train)
str(train)
```
train数据集199523*41.
```{r}
dim(test)
str (test)
```
test数据集99762*41.

##查看因变量take a look at target variable
```{r}
unique(train$income_level)
unique(test$income_level)
```

##编码因变量encode target variables
```{r}
# 将目标变量取值替换为0,1，ifelse(test,yes,no)
train[, income_level := ifelse(income_level == "-50000",0,1)]
test[, income_level := ifelse(income_level == "-50000",0,1)]
```

##查看训练集的正负样本分布情况
```{r}
round(prop.table(table(train$income_level))*100)
```
从返回结果可以看出，原始训练集的正负样本分布非常不均衡，收入水平小于5万的人群占据了94%，大于5万的人群仅仅占了6%（毕竟有钱人还是少！），这是一个典型的不平衡数据集，正负样本差别太大，则会对模型的准确性造成误解。例如有98个正例，2个反例，那么只需要建立一个永远返回正例的预测模型就能轻松达到98%的精确度，这样显然是不合理的。那么如何由这种不平衡数据集学习到一个准确预测收入水平的模型呢？这是主要要解决的难题。

#数据预处理
首先，从数据集介绍的页面可以了解到，变量被分为nominal（名义型）和continuous（连续型）两种类型，即分别对应类别型和数值型。
对数据进行预处理时，首先要解决的便是将这两种不同的数据类型切分开来，data.table包可以帮助我们快速简单地完成这个任务。

```{r}
#数据集介绍的页面已经告诉我们哪些特征为nominal或是continuous
factcols <- c(2:5,7,8:16,20:29,31:38,40,41)
numcols <- setdiff(1:40,factcols)
# lapply的.SD的用法
#DT[, .SD, .SDcols=x:y]  #用.SDcols 定义SubDadaColums（子列数据)，这里取出x到y之间的列作为子集，然后.SD 输出所有子集
train[,(factcols) := lapply(.SD, factor), .SDcols = factcols][,(numcols) := lapply(.SD, as.numeric), .SDcols = numcols]
test[,(factcols) := lapply(.SD, factor), .SDcols = factcols][,(numcols) := lapply(.SD, as.numeric), .SDcols = numcols]
# 将训练集和测试集中的类别变量和数值变量分别提取出来
cat_train <- train[,factcols, with=FALSE]
cat_test <- test[,factcols,with=FALSE]
num_train <- train[,numcols,with=FALSE]
num_test <- test[,numcols,with=FALSE]
rm(train,test) 
```

#数据可视化
单纯查看数据集无法得到直观的感受，“一图胜千言”，图形是最简单直观的办法，下面我们会用到ggplot2和plotly两个强大的绘图包。
```{r}
# geom_histogram()直方图
# geom_density()密度图
# aes设定x轴y轴的名称
plot_dist <- function(a){
  ggplot(data = num_train, aes(x= a, y=..density..)) + geom_histogram(fill="green",color="white",
                                        alpha = 0.5,bins =100) + geom_density()
  ggplotly()
}
plot_dist(num_train$age)
plot_dist(num_train$wage_per_hour)
```
以上两个分布图符合我们的常识，年龄分布在0~90岁之间，年龄越大，所占比例越小。

##自变量与因变量之间的关系

我们分别考虑训练集中的数值型变量和类别型变量与income_level的关系。
首先看数值型的，数值型训练集num_train下有wage_per_hour、capital_gains、capital_losses、dividend_from_Stocks等等几个变量，我们选取了四个关联程度较大的指标，可以看出，大部分年龄段处于25-65的人收入水平income_level为1（大于50000），他们的小时工资（wage per hour）处在1000美元到4000美元的水平。这个事实进一步强化了我们认为年龄小于20的人收入水平小于50000的假设。
```{r}
#income_level属于类别型的，被切分到了cat_train中
#:=是data.table添加一列
num_train[,income_level := cat_train$income_level]
ggplot(data=num_train,aes(x = age,
y=wage_per_hour))+geom_point(aes(colour=income_level))+scale_y_continuous("wage per
hour", breaks = seq(0,10000,1000))
```

股票收益对收入的影响也是比较大的，收入水平大于50000的人群基本上股票分红都超过了30000美元
```{r}
ggplot(data=num_train,aes(x = age,y=dividend_from_Stocks))+geom_point(aes(colour=income_level))+
  scale_y_continuous("dividend from stocks", breaks = seq(0,10000,5000))
```

```{r}
ggplot(data = num_train, aes(x = weeks_worked_in_year, y = wage_per_hour)) +
  geom_point(aes(colour = income_level)) +
  scale_y_continuous("wage per hour", breaks = seq(0,10000,1000))
```

我们也可以将分类变量以可视化的形式展现出来，对于类别数据，dodged条形图比一般条形图能展更多的信息。在dodged条形图中，可以发现很多有趣的东西，比如本科毕业生年薪超过5万的人数最多，拥有博士学位的人年薪超过5万和低于5万的比例是相同的，白人年薪超过5万的人群远远多于其他肤色的种族
```{r}
plot_dodgedbar <- function(a){
  ggplot(cat_train, aes(x = a, fill = income_level)) +
    geom_bar(position = 'dodge', color = 'black') + 
    scale_fill_brewer(palette = 'Pastel1') + 
    theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 10))
}
plot_dodgedbar(cat_train$class_of_worker)
plot_dodgedbar(cat_train$education)
plot_dodgedbar(cat_train$enrolled_in_edu_inst_lastwk)
plot_dodgedbar(cat_train$marital_status)
plot_dodgedbar(cat_train$major_industry_code)
plot_dodgedbar(cat_train$major_occupation_code)
```

```{r}
prop.table(table(cat_train$class_of_worker, cat_train$income_level),1)
prop.table(table(cat_train$marital_status, cat_train$income_level),1)
```

#数据清洗DATA CLEANING
##检查遗漏值
数据清洗时数据分析的一个重要步骤，首先检查训练集和测试集中是否有遗漏值
```{r}
table(is.na(num_train))
table(is.na(num_test))
num_train[, income_level := NULL]
```
从反馈的结果来看，FALSE分别等于1596184=199523×8，698334=99762×7，故训练集和测试集中没有一个遗漏值，这是一个不错的消息！

##删除高度相关变量
```{r}
correlatedvars <- findCorrelation(x = cor(num_train), cutoff = 0.7)
correlatedvars
num_train <-num_train[, -correlatedvars, with = FALSE]
num_test <- num_test[, -correlatedvars, with = FALSE]
```
筛选的结果显示，weeks_worked_in_year变量与其他变量存在相当高的相关性。这很好理解，因为一年之中工作的时间越长那么相应的工资、回报也会随之上涨，所以要把这个高度相关性的变量剔除掉，这样num_train当中就只剩下7个变量了。

```{r}
missingvaluesprop_train <- sapply(cat_train, function(x){sum(is.na(x))/length(x)})*100 
missingvaluesprop_train
missingvaluesprop_test <- sapply(cat_test, function(x){sum(is.na(x))/length(x)})*100
missingvaluesprop_test
```
大部分的列情况比较乐观，但是有的列甚至有超过50%的数据遗漏（这有可能是由于采集数据难度所致，特别是人口普查），将遗漏率小于5%的列挑选出来，遗漏率太高的变量剔除掉。
```{r}
cat_train <- subset(cat_train, select = missingvaluesprop_train < 5)
cat_test <- subset(cat_test, select = missingvaluesprop_test < 5)
```
set NA as Unavailable - train data
```{r}
#convert to characters
cat_train <- cat_train[,names(cat_train) := lapply(.SD, as.character),.SDcols = names(cat_train)]
for (i in seq_along(cat_train)){ 
  set(cat_train, i=which(is.na(cat_train[[i]])), j=i, value="Unavailable")
}
str(cat_train)
```

```{r}
#convert back to factors
cat_train <- cat_train[, names(cat_train) := lapply(.SD,factor), .SDcols = names(cat_train)]
str(cat_train)
```

set NA as Unavailable - test data
```{r}
cat_test <- cat_test[, (names(cat_test)) := lapply(.SD, as.character), .SDcols = names(cat_test)]
for (i in seq_along(cat_test)){ 
  set(cat_test, i=which(is.na(cat_test[[i]])), j=i, value="Unavailable")
}
str(cat_test)
```

```{r}
#convert back to factors
cat_test <- cat_test[, (names(cat_test)) := lapply(.SD, factor), .SDcols = names(cat_test)]
str(cat_test)
```

#数据操作——规范化处理DATA MANIPULATION
在前面的分析中，有的类别变量下个别水平出现的频率很低，这样的数据对我们的分析作用不是特别大。在接下来的步骤中，我们的任务是将这些变量下频率低于5%的水平字段 设置为"Other"。处理完类别型数据之后，对于数值型数据，各个变量下的水平分布过于稀疏，所以需要将其规范化。
```{r}
#将cat_train和cat_test中每列下出现频率低于5%的水平设置为“Other”
#train
for(i in names(cat_train)){
  p <- 5/100
  ld <- names(which(prop.table(table(cat_train[[i]])) < p))
  levels(cat_train[[i]])[levels(cat_train[[i]]) %in% ld] <- "Other"
}
#test
for(i in names(cat_test)){
  p <- 5/100
  ld <- names(which(prop.table(table(cat_test[[i]])) < p))
  levels(cat_test[[i]])[levels(cat_test[[i]]) %in% ld] <- "Other"
}
```

```{r}
#"nlevs"参数：返回每列下维度的个数，测试集和训练集是否匹配
summarizeColumns(cat_train)[, 'nlevs']
summarizeColumns(cat_test)[, 'nlevs']
```

```{r}
num_train[, .N, age][order(age)]
num_train[, .N, wage_per_hour][order(-N)]
```

```{r}
#以0，30，90为分隔点，将年龄段划分为三个区段，“young”，“adult”，“old”
num_train[, age := cut(age, breaks = c(0,30,60,90), labels = c("young","adult","old"),
                       include.lowest = TRUE)]
num_test[, age := cut(age, breaks = c(0,30,60,90), labels = c("young","adult","old"),
                       include.lowest = TRUE)]
```

```{r}
#将wage_per_hour，capital_gains，capital_losses，dividend_from_Stocks设置为只有0和大于0两个水平
num_train[,wage_per_hour := ifelse(wage_per_hour == 0,"Zero","MoreThanZero")][,wage_per_hour := as.factor(wage_per_hour)]
num_train[,capital_gains := ifelse(capital_gains == 0,"Zero","MoreThanZero")][,capital_gains := as.factor(capital_gains)]
num_train[,capital_losses := ifelse(capital_losses == 0,"Zero","MoreThanZero")][,capital_losses := as.factor(capital_losses)]
num_train[,dividend_from_Stocks := ifelse(dividend_from_Stocks == 0,"Zero","MoreThanZero")][,dividend_from_Stocks := as.factor(dividend_from_Stocks)]
num_test[,wage_per_hour := ifelse(wage_per_hour == 0,"Zero","MoreThanZero")][,wage_per_hour := as.factor(wage_per_hour)]
num_test[,capital_gains := ifelse(capital_gains == 0,"Zero","MoreThanZero")][,capital_gains := as.factor(capital_gains)]
num_test[,capital_losses := ifelse(capital_losses == 0,"Zero","MoreThanZero")][,capital_losses := as.factor(capital_losses)]
num_test[,dividend_from_Stocks := ifelse(dividend_from_Stocks == 0,"Zero","MoreThanZero")][,dividend_from_Stocks := as.factor(dividend_from_Stocks)]
```

#模型开发MODEL DEVELOPMENT
```{r}
train <- cbind(num_train, cat_train)
test <- cbind(num_test, cat_test)
train.task <- makeClassifTask(data = train, target = "income_level")
test.task<- makeClassifTask(data = test, target = "income_level")
```

```{r}
#remove constant variables with no variance
train.task <- removeConstantFeatures(train.task)
test.task <- removeConstantFeatures(test.task)
```

应对不平衡数据集，通常的技巧有上采样(oversampling)、下采样(undersampling)，以及过采样的一种代表性方法SMOTE(Synthetic Minority Oversampling TEchnique)算法。
上采样：即增加一些正例使得正、反例数目接近，然后再进行学习
下采样：去除一些反例使得正、反例数目接近，然后进行学习
SMOTE：通过对训练集里的正例进行插值来产生额外的正例，主要思想是通过在一些位置相近的少数类样本中插入新样本来达到平衡的目的

下采样法的时间开销通常远远小于上采样法，因为前者丢弃了很多反例，使得训练集远小于初始训练集，下采样另外一个可能的缺陷在于它可能会导致信息的丢失。上采样法增加了很多正例，训练集的大小大于初始训练集，训练时间开销变大，而且容易导致过拟合。
更多关于SMOTE采样方法，Chawla 的这篇文章有详细的说明。

```{r}
train_under <- undersample(train.task, rate = 0.1)
table(getTaskTargets(train_under))

train_over <- oversample(train.task, rate = 15)
table(getTaskTargets(train_over))

train.smote <- smote(train.task,rate = 10,nn = 3) 
table(getTaskTargets(train.smote))
```
##选择算法
进行完特征工程等数据清洗工作，我们就开始建模的过程，在建立模型之前，如何快速选择合适的学习算法又是重中之重，那么mlr给出了非常人性的方法。通过listLearners()可以查看所有涉及到的算法以及相应的数据要求
指定条件，选择适用的算法
```{r}
listLearners("classif","twoclass")[c("class","package")]
```

##朴素贝叶斯
```{r}
#naive Bayes
naive_learner <- makeLearner("classif.naiveBayes",predict.type = "response")
naive_learner$par.vals <- list(laplace = 1)
```

##10folds交叉验证
```{r}
#10fold CV - stratified
folds <- makeResampleDesc("CV",iters=10,stratify = TRUE)
```

##交叉验证函数
```{r}
#cross validation function
fun_cv <- function(a){
  crv_val <- resample(naive_learner,a,folds,measures = list(acc,tpr,tnr,fpr,fp,fn))
  crv_val$aggr
}
#Lets check whether train data or smoted train data is better
# 训练结果，从训练结果得知，对不平衡数据集采取不同的采样
# 方法得出的结果截然不同
fun_cv(train.task)
fun_cv(train.smote)
```

## 训练和预测
```{r}
#train and predict
nB_model <- mlr::train(naive_learner, train.smote)
nB_predict <- predict(nB_model, test.task)
```

## 模型评估
```{r}
#evaluate
nB_prediction <- nB_predict$data$response
dCM <- confusionMatrix(test$income_level,nB_prediction)
dCM
```
准确率precision ：0.844
召回率recall 0.985
Specificity（真阴性率）：0.254

## F值
```{r}
#calculate F measure
precision <- dCM$byClass['Pos Pred Value']
recall <- dCM$byClass['Sensitivity']
specificity <- dCM$byClass['Specificity']
# F值
f_measure <- 2*((precision*recall)/(precision+recall))
f_measure 
```
由实验结果，学习得到的模型达到0.844的准确率和0.985的召回率，而真反例仅仅为0.254。这就说明模型在预测正例上表现良好，而对个数较少的反例预测精度不高。这样的结果不太令人满意，在接下来的文章中我们继续探讨其他模型是不是有更好的效果。
